{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import polars as pl\n",
    "import markout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pools\n",
    "# TODO: can I totally skip this step? Ideally you could build it as an add-on feature to make the analysis extensible.\n",
    "pools = (\n",
    "    # see pools.sql\n",
    "    pl.read_csv('2024.5.2 uniswap pools for markout analysis.csv')\n",
    "    # I need to filter out for WETH pairs only because I don't have USDC values for everything else\n",
    "    # I'm filtering in the Python rather than the SQL so that it's extensible to USDC in the future.\n",
    "    .filter(\n",
    "        (pl.col('TOKEN0_ADDRESS') == '0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2')\n",
    "        |\n",
    "        (pl.col('TOKEN1_ADDRESS') == '0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2')\n",
    "    )\n",
    "    .with_columns(\n",
    "        FEE = (pl.col('FEE')/100).cast(pl.Int8),\n",
    "        # whether WETH is token0 or not\n",
    "        # TODO: can I remove this and pass decimals to the markout?\n",
    "        IS_WETH_TOKEN0 = (\n",
    "            pl.when(pl.col('TOKEN0_ADDRESS') == '0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2')\n",
    "            .then(True)\n",
    "            .otherwise(False)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pools.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FYI BOB/WETH is 0x3887e82dbdbe8ec6db44e6298a2d48af572a3b78\n",
    "swaps = markout.loadSwaps()\n",
    "\n",
    "swaps.head(10000).write_csv('swaps_cut.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the volume per-row\n",
    "\n",
    "(swaps\n",
    " .with_columns(\n",
    "     volume = pl\n",
    "        .when(pl.col('token0_symbol') == 'WETH') # if WETH is in token0 slot\n",
    "        .then(pl.col('amount0')/(10 ** pl.col('token0_decimals'))) # then volume (in WETH) = amount0, decimal-adjusted\n",
    "        .otherwise(pl.col('amount1')/(10 ** pl.col('token1_decimals'))) # otherwise, WETH is in token1 slot and volume (in WETH = amount1, decimal adjusted)\n",
    " )\n",
    " .head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swaps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markout_data = (pl.DataFrame(data = {\n",
    "    # address of the liquidity pool. Assume I have many pools\n",
    "    'address': ['0x88e6A0c2dDD26FEEb64F039a2c41296FcB3f5640',\n",
    "                '0x88e6A0c2dDD26FEEb64F039a2c41296FcB3f5640',\n",
    "                '0x88e6A0c2dDD26FEEb64F039a2c41296FcB3f5640',\n",
    "                '0x88e6A0c2dDD26FEEb64F039a2c41296FcB3f5640', \n",
    "                '0xdce93ed9ae7c53143e19cf799d156b72d1cc2777'],\n",
    "    # decimal-adjusted price of a trade\n",
    "    'execution_price': [3000,\n",
    "                        3010,\n",
    "                        3020,\n",
    "                        3030,\n",
    "                        5000000],\n",
    "    # timestamp of the trade when it occurred\n",
    "    # you can see that the price is slowly ascending over time\n",
    "    'timestamp': ['2023-08-07T16:16:59.000000',\n",
    "                  '2023-08-07T16:20:58.000000', # + 4m 59s\n",
    "                  '2023-08-07T16:22:58.000000', # + 2m 00s\n",
    "                  '2023-08-07T16:27:59.000000', # + 5m 01s\n",
    "                  '2023-08-07T16:27:59.000000'], # partition by address\n",
    "    'five_min_markout_price_should_be': [3010, # the trade in this row executed at 16:59. Skip to 21:59 then skip backwards to the latest execution price.\n",
    "                                         3020, # the trade in this row executed at 20:58. Skip to 25:58 then skip backwards to the latest execution price.\n",
    "                                         3020, # the trade in this row executed at 22:58. Skip to 27:58 then skip backwards to the latest execution price.\n",
    "                                         3030, # the trade in this row executed at 27:59. Skip to 32:59 then skip backwards to the latest execution price.\n",
    "                                         5000000] # partition by address\n",
    "}).with_columns(\n",
    "    pl.col('timestamp').str.strptime(pl.Datetime)\n",
    ")\n",
    ")\n",
    "\n",
    "markout_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the markout price per-row\n",
    "\n",
    "(markout_data.join_asof(\n",
    "    other=markout_data.select(\n",
    "        pl.col('timestamp').dt.offset_by('-5m').alias('timestamp_plus_five_min'),\n",
    "        pl.col('execution_price'),\n",
    "        pl.col('address')\n",
    "    ),\n",
    "    left_on='timestamp',\n",
    "    right_on='timestamp_plus_five_min',\n",
    "    by='address',\n",
    "    strategy='backward'\n",
    ").rename({'execution_price_right': 'markout_price'})\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liquidity_pool_address = testing['liquidity_pool_address'].unique().first()\n",
    "\n",
    "liquidity_pool_address = testing.select(pl.first('liquidity_pool_address'))[0]\n",
    "\n",
    "filtered_df = testing.filter(pl.col('liquidity_pool_address') == liquidity_pool_address)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(filtered_df\n",
    " .select(['block_timestamp', 'adj_price', 'markout_5m'])\n",
    " .write_csv(file='testing.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    TODO:\n",
    "    something like\n",
    "    for pool in \"pools\", which is a pl.DataFrame\n",
    "    get the pool address and chain\n",
    "    call load_all_swaps, which returns a pl.DataFrame\n",
    "    pass the df, TOKEN0_DECIMALS, TOKEN1_DECIMALS, IS_WETH_TOKEN0, and weth_prices to construct_markout\n",
    "    call execute_markout, which returns a pl.DataFrame\n",
    "    append the DataFrame to \"results\", a pl.DataFrame\n",
    "\"\"\"\n",
    "\n",
    "def process_pools(pools: pl.DataFrame) -> pl.DataFrame:\n",
    "    # Initialize an empty list to store the results\n",
    "    results = []\n",
    "\n",
    "    for pool in pools.iter_rows(named=True):\n",
    "\n",
    "        pool_address = pool['LIQUIDITY_POOL_ADDRESS']\n",
    "        chain = 'ethereum' \n",
    "        # TODO: lint - these should be lowercase\n",
    "        TOKEN0_DECIMALS = pool['TOKEN0_DECIMALS']\n",
    "        TOKEN1_DECIMALS = pool['TOKEN1_DECIMALS']\n",
    "        IS_WETH_TOKEN0 = pool['IS_WETH_TOKEN0']\n",
    "        fee = pool['FEE']\n",
    "\n",
    "        # Load all swaps for the current pool\n",
    "        swaps_df = markout.load_all_swaps(pool_address, chain)\n",
    "\n",
    "        # Construct the markout DataFrame\n",
    "        markout_df = markout.construct_markout(swaps_df, TOKEN0_DECIMALS, TOKEN1_DECIMALS, IS_WETH_TOKEN0)\n",
    "\n",
    "        # Execute the markout calculation\n",
    "        markout_result = markout.execute_markout(markout_df)\n",
    "\n",
    "        # Add pool information to the result\n",
    "        markout_result['pool_address'] = pool_address\n",
    "        markout_result['chain'] = chain\n",
    "        markout_result['fee'] = fee\n",
    "\n",
    "        # Append the result to the list\n",
    "        results.append(markout_result)\n",
    "\n",
    "    # Convert the list of results to a Polars DataFrame\n",
    "    result_df = pl.from_dicts(results)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# Assuming you have a DataFrame called 'pools' with pool information\n",
    "# and a DataFrame called 'weth_prices' with WETH price data\n",
    "result_df = process_pools(pools)\n",
    "\n",
    "# TODO: then plot. x axis as volume, y axis as markout, can plot fee as dot color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_results = (result_df.explode('total_volume', 'total_markout')\n",
    "      .filter(\n",
    "          (pl.col('total_volume') != 0.0) &\n",
    "          (pl.col('total_markout') > -508827)\n",
    "      )\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_results.select([\"total_volume\", \"total_markout\"]).plot.scatter(x=\"total_volume\", y=\"total_markout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.explode(['total_volume', 'total_markout']).head()\n",
    "# result_df.explode(['total_volume_usd', 'total_markout_usd']).head().write_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df = result_df.explode(['total_volume', 'total_markout'])\n",
    "\n",
    "exploded_df.select([\"total_volume\", \"total_markout\"]).plot.scatter(x=\"total_volume\", y=\"total_markout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
